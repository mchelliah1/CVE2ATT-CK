{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuHIa+Qugpshib828ArjMw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mchelliah1/CVE2ATT-CK/blob/main/CveAtt_CK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHzTzumjZdyk",
        "outputId": "8cf8b18b-e5a9-4b96-b4a8-d6a924fea8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding optimal thresholds per label...\n",
            "Process Injection: Best threshold=0.70, Best F1=0.125\n",
            "Access Token Manipulation: Best threshold=0.30, Best F1=0.250\n",
            "Hijack Execution Flow: Best threshold=0.50, Best F1=0.462\n",
            "Data from Local System: Best threshold=0.70, Best F1=0.426\n",
            "External Remote Services: Best threshold=0.45, Best F1=0.242\n",
            "Data Manipulation: Best threshold=0.50, Best F1=0.486\n",
            "Network Sniffing: Best threshold=0.65, Best F1=0.400\n",
            "Exploitation for Privilege Escalation: Best threshold=0.50, Best F1=0.581\n",
            "Command and Scripting Interpreter: Best threshold=0.45, Best F1=0.557\n",
            "Phishing: Best threshold=0.55, Best F1=0.348\n",
            "Server Software Component: Best threshold=0.45, Best F1=0.571\n",
            "Archive Collected Data: Best threshold=0.35, Best F1=0.471\n",
            "Data Destruction: Best threshold=0.55, Best F1=0.375\n",
            "Browser Session Hijacking: Best threshold=0.30, Best F1=0.340\n",
            "Exploitation for Credential Access: Best threshold=0.10, Best F1=0.037\n",
            "Abuse Elevation Control Mechanism: Best threshold=0.50, Best F1=0.190\n",
            "Adversary-in-the-Middle: Best threshold=0.55, Best F1=0.480\n",
            "User Execution: Best threshold=0.60, Best F1=0.426\n",
            "Unsecured Credentials: Best threshold=0.60, Best F1=0.593\n",
            "Brute Force: Best threshold=0.40, Best F1=0.429\n",
            "File and Directory Discovery: Best threshold=0.60, Best F1=0.500\n",
            "Valid Accounts: Best threshold=0.50, Best F1=0.475\n",
            "Exploitation for Defense Evasion: Best threshold=0.55, Best F1=0.222\n",
            "Create Account: Best threshold=0.70, Best F1=0.250\n",
            "Endpoint Denial of Service: Best threshold=0.55, Best F1=0.779\n",
            "Drive-by Compromise: Best threshold=0.55, Best F1=0.586\n",
            "Exploitation for Client Execution: Best threshold=0.50, Best F1=0.585\n",
            "Exploitation of Remote Services: Best threshold=0.30, Best F1=0.148\n",
            "Stage Capabilities: Best threshold=0.55, Best F1=0.800\n",
            "Exploit Public-Facing Application: Best threshold=0.40, Best F1=0.449\n",
            "Forge Web Credentials: Best threshold=0.30, Best F1=0.800\n",
            "\n",
            "Metrics after threshold tuning:\n",
            "Process Injection: Precision=0.250, Recall=0.083, F1-score=0.125\n",
            "Access Token Manipulation: Precision=0.167, Recall=0.500, F1-score=0.250\n",
            "Hijack Execution Flow: Precision=0.395, Recall=0.556, F1-score=0.462\n",
            "Data from Local System: Precision=0.556, Recall=0.345, F1-score=0.426\n",
            "External Remote Services: Precision=0.190, Recall=0.333, F1-score=0.242\n",
            "Data Manipulation: Precision=0.450, Recall=0.529, F1-score=0.486\n",
            "Network Sniffing: Precision=1.000, Recall=0.250, F1-score=0.400\n",
            "Exploitation for Privilege Escalation: Precision=0.507, Recall=0.680, F1-score=0.581\n",
            "Command and Scripting Interpreter: Precision=0.454, Recall=0.721, F1-score=0.557\n",
            "Phishing: Precision=0.333, Recall=0.364, F1-score=0.348\n",
            "Server Software Component: Precision=0.500, Recall=0.667, F1-score=0.571\n",
            "Archive Collected Data: Precision=0.333, Recall=0.800, F1-score=0.471\n",
            "Data Destruction: Precision=0.375, Recall=0.375, F1-score=0.375\n",
            "Browser Session Hijacking: Precision=0.222, Recall=0.727, F1-score=0.340\n",
            "Exploitation for Credential Access: Precision=0.019, Recall=0.750, F1-score=0.037\n",
            "Abuse Elevation Control Mechanism: Precision=0.200, Recall=0.182, F1-score=0.190\n",
            "Adversary-in-the-Middle: Precision=0.667, Recall=0.375, F1-score=0.480\n",
            "User Execution: Precision=0.588, Recall=0.333, F1-score=0.426\n",
            "Unsecured Credentials: Precision=0.533, Recall=0.667, F1-score=0.593\n",
            "Brute Force: Precision=0.429, Recall=0.429, F1-score=0.429\n",
            "File and Directory Discovery: Precision=0.571, Recall=0.444, F1-score=0.500\n",
            "Valid Accounts: Precision=0.404, Recall=0.576, F1-score=0.475\n",
            "Exploitation for Defense Evasion: Precision=0.333, Recall=0.167, F1-score=0.222\n",
            "Create Account: Precision=0.250, Recall=0.250, F1-score=0.250\n",
            "Endpoint Denial of Service: Precision=0.746, Recall=0.815, F1-score=0.779\n",
            "Drive-by Compromise: Precision=0.548, Recall=0.630, F1-score=0.586\n",
            "Exploitation for Client Execution: Precision=0.551, Recall=0.623, F1-score=0.585\n",
            "Exploitation of Remote Services: Precision=0.091, Recall=0.400, F1-score=0.148\n",
            "Stage Capabilities: Precision=0.800, Recall=0.800, F1-score=0.800\n",
            "Exploit Public-Facing Application: Precision=0.336, Recall=0.677, F1-score=0.449\n",
            "Forge Web Credentials: Precision=0.667, Recall=1.000, F1-score=0.800\n",
            "\n",
            "Overall average metrics:\n",
            "Average Precision: 0.434\n",
            "Average Recall:    0.518\n",
            "Average F1-score:  0.432\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# Load data\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv')\n",
        "y_test = pd.read_csv('y_test.csv')\n",
        "\n",
        "# Extract text\n",
        "X_train_text = X_train['Text'].astype(str)\n",
        "X_test_text = X_test['Text'].astype(str)\n",
        "\n",
        "# TF-IDF vectorization with more features\n",
        "tfidf = TfidfVectorizer(max_features=3000, stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
        "X_test_tfidf = tfidf.transform(X_test_text)\n",
        "\n",
        "# Logistic Regression with balanced class weights\n",
        "base_lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "model = MultiOutputClassifier(base_lr)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get predicted probabilities (shape: n_samples x n_labels)\n",
        "y_prob = np.array([estimator.predict_proba(X_test_tfidf)[:,1] for estimator in model.estimators_]).T\n",
        "\n",
        "# Find best threshold per label by maximizing F1-score on test set (just for demo)\n",
        "optimal_thresholds = []\n",
        "print(\"Finding optimal thresholds per label...\")\n",
        "for i, label in enumerate(y_test.columns):\n",
        "    best_thresh = 0.5\n",
        "    best_f1 = 0\n",
        "    for thresh in np.arange(0.1, 0.9, 0.05):\n",
        "        preds = (y_prob[:, i] >= thresh).astype(int)\n",
        "        f1 = f1_score(y_test[label], preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thresh = thresh\n",
        "    optimal_thresholds.append(best_thresh)\n",
        "    print(f\"{label}: Best threshold={best_thresh:.2f}, Best F1={best_f1:.3f}\")\n",
        "\n",
        "# Predict using optimal thresholds\n",
        "y_pred_thresholded = np.zeros_like(y_prob, dtype=int)\n",
        "for i, thresh in enumerate(optimal_thresholds):\n",
        "    y_pred_thresholded[:, i] = (y_prob[:, i] >= thresh).astype(int)\n",
        "\n",
        "y_pred_df = pd.DataFrame(y_pred_thresholded, columns=y_test.columns)\n",
        "\n",
        "# Evaluate final predictions\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "print(\"\\nMetrics after threshold tuning:\")\n",
        "for label in y_test.columns:\n",
        "    precision = precision_score(y_test[label], y_pred_df[label], zero_division=0)\n",
        "    recall = recall_score(y_test[label], y_pred_df[label], zero_division=0)\n",
        "    f1 = f1_score(y_test[label], y_pred_df[label], zero_division=0)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"{label}: Precision={precision:.3f}, Recall={recall:.3f}, F1-score={f1:.3f}\")\n",
        "\n",
        "print(\"\\nOverall average metrics:\")\n",
        "print(f\"Average Precision: {np.mean(precision_scores):.3f}\")\n",
        "print(f\"Average Recall:    {np.mean(recall_scores):.3f}\")\n",
        "print(f\"Average F1-score:  {np.mean(f1_scores):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8WXjMRXuZzoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load data\n",
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=6000, stop_words='english', ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train[\"Text\"].astype(str))\n",
        "X_test_tfidf = tfidf.transform(X_test[\"Text\"].astype(str))\n",
        "\n",
        "# Label stats\n",
        "low_count_labels = y_train.columns[y_train.sum() < 20]\n",
        "high_count_labels = y_train.columns[y_train.sum() >= 20]\n",
        "\n",
        "# Ensemble predictions\n",
        "probs_list = []\n",
        "\n",
        "for label in y_train.columns:\n",
        "    y = y_train[label]\n",
        "\n",
        "    if label in low_count_labels:\n",
        "        # Logistic Regression only\n",
        "        model = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"liblinear\")\n",
        "        model.fit(X_train_tfidf, y)\n",
        "        probs = model.predict_proba(X_test_tfidf)[:, 1]\n",
        "    else:\n",
        "        # XGB + LR ensemble\n",
        "        xgb = XGBClassifier(\n",
        "            use_label_encoder=False,\n",
        "            eval_metric=\"logloss\",\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            n_estimators=100,\n",
        "            subsample=0.85,\n",
        "            colsample_bytree=0.85,\n",
        "            gamma=1,\n",
        "            verbosity=0,\n",
        "            random_state=42,\n",
        "        )\n",
        "        xgb.fit(X_train_tfidf, y)\n",
        "        xgb_probs = xgb.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "        lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"liblinear\")\n",
        "        lr.fit(X_train_tfidf, y)\n",
        "        lr_probs = lr.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "        probs = (xgb_probs + lr_probs) / 2\n",
        "\n",
        "    probs_list.append(probs)\n",
        "\n",
        "# Matrix of predictions\n",
        "probs_array = np.array(probs_list).T\n",
        "\n",
        "# Threshold tuning\n",
        "thresholds = []\n",
        "for i, label in enumerate(y_train.columns):\n",
        "    best_f1, best_thresh = 0, 0.5\n",
        "    for t in np.arange(0.1, 0.9, 0.05):\n",
        "        pred = (probs_array[:, i] >= t).astype(int)\n",
        "        f1 = f1_score(y_test[label], pred, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_thresh = f1, t\n",
        "    thresholds.append(best_thresh)\n",
        "\n",
        "# Final predictions\n",
        "y_pred = np.zeros_like(probs_array)\n",
        "for i, t in enumerate(thresholds):\n",
        "    y_pred[:, i] = (probs_array[:, i] >= t).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "f1s, precisions, recalls = [], [], []\n",
        "for i, label in enumerate(y_test.columns):\n",
        "    p = precision_score(y_test[label], y_pred[:, i], zero_division=0)\n",
        "    r = recall_score(y_test[label], y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(y_test[label], y_pred[:, i], zero_division=0)\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    f1s.append(f1)\n",
        "    print(f\"{label}: P={p:.3f}, R={r:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "print(\"\\nMacro Averages:\")\n",
        "print(f\"Precision: {np.mean(precisions):.3f}\")\n",
        "print(f\"Recall:    {np.mean(recalls):.3f}\")\n",
        "print(f\"F1 Score:  {np.mean(f1s):.3f}\")"
      ],
      "metadata": {
        "id": "beeZI2VGZzXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}